{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Load Network(coco)\n",
    "#protoFile = \"pose_deploy_linevec.prototxt\"\n",
    "protoFile = 'pose_deploy_linevec_faster_4_stages.prototxt'\n",
    "weightsFile = \"pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "# POSE_PAIRS = [[1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "BODY_PARTS = { \"Head\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Chest\": 14,\n",
    "                \"Background\": 15 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Head\", \"Neck\"], [\"Neck\", \"RShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                [\"RElbow\", \"RWrist\"], [\"Neck\", \"LShoulder\"], [\"LShoulder\", \"LElbow\"],\n",
    "                [\"LElbow\", \"LWrist\"], [\"Neck\", \"Chest\"], [\"Chest\", \"RHip\"], [\"RHip\", \"RKnee\"],\n",
    "                [\"RKnee\", \"RAnkle\"], [\"Chest\", \"LHip\"], [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    t = time.time()\n",
    "    hasFrame, frame = cap.read()\n",
    "    frameCopy = np.copy(frame)   \n",
    "    if not hasFrame:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "    ## 2. Read Video and Prepare Input to the network\n",
    "    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    # Fix the input Height and get the width according to the Aspect Ratio\n",
    "    inHeight = 368 \n",
    "    inWidth = int((inHeight/frameHeight)*frameWidth)\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    net.setInput(inpBlob)\n",
    "    output = net.forward()\n",
    "    \n",
    "    ## 3. Make Predictions and Parse Keypoints\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "    points = []\n",
    "    for i in range(nPoints):\n",
    "        probMap = output[0, i, :, :]\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "        if prob > threshold : \n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append(None)\n",
    "            \n",
    "#     for pair in POSE_PAIRS:\n",
    "#         partA = pair[0]\n",
    "#         partB = pair[1]\n",
    "#         if points[partA] and points[partB]:\n",
    "#             cv2.line(frame, points[partA], points[partB], (0, 255, 255), 3, lineType=cv2.LINE_AA)\n",
    "#             cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "#             cv2.circle(frame, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "#     cv2.putText(frame, \"Test Time = {:.2f} sec\".format(time.time() - t), (50, 50), cv2.FONT_HERSHEY_COMPLEX, .8, (255, 50, 0), 2, lineType=cv2.LINE_AA)\n",
    "    #cv2.imshow('result', frameCopy)\n",
    "    \n",
    "    for pair in POSE_PAIRS:  # 각 POSE_PAIRS별로 선 그어줌 (머리 - 목, 목 - 왼쪽어깨, ...)\n",
    "        partA = pair[0]             # Head\n",
    "        partA = BODY_PARTS[partA]   # 0\n",
    "        partB = pair[1]             # Neck\n",
    "        partB = BODY_PARTS[partB]   # 1\n",
    "        #print(partA,\" 와 \", partB, \" 연결\\n\")\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frameCopy, points[partA], points[partB], (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Output-Keypoints\", frameCopy)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):          \n",
    "        break\n",
    "\n",
    "cap.release()                               \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
